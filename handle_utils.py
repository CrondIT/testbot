"""Utility functions for handling user interactions,
messages, and edit modes."""

import os
import io
from PIL import Image
import google.generativeai as genai
import dbbot
import token_utils
import file_utils
import billing_utils
import models_config
from telegram import Update
from telegram.ext import ContextTypes
from telegram.helpers import escape_markdown


# Global variables that need to be accessible
user_contexts = {}  # –•—Ä–∞–Ω–∏–ª–∏—â–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ —Ä–µ–∂–∏–º–∞
user_modes = {}  # –•—Ä–∞–Ω–∏—Ç —Ç–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
user_edit_data = {}  # –•—Ä–∞–Ω–∏—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
user_file_data = {}  # –•—Ä–∞–Ω–∏—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ñ–∞–π–ª–æ–≤
MAX_CONTEXT_MESSAGES = 4


async def download_and_convert_image(
    file_id: str, context: ContextTypes.DEFAULT_TYPE
) -> io.BytesIO:
    """
    –°–∫–∞—á–∏–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –≤ PNG
    –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –µ–≥–æ –≤ –≤–∏–¥–µ BytesIO
    """
    file = await context.bot.get_file(file_id)
    image_data = io.BytesIO()
    await file.download_to_memory(out=image_data)
    image_data.seek(0)
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ PNG
    try:
        with Image.open(image_data) as img:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB –µ—Å–ª–∏ –Ω—É–∂–Ω–æ (–¥–ª—è JPEG)
            if img.mode in ("P", "RGBA", "LA"):
                # –°–æ–∑–¥–∞–µ–º –±–µ–ª—ã–π —Ñ–æ–Ω –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å—é
                background = Image.new("RGB", img.size, (255, 255, 255))
                if img.mode == "P":
                    img = img.convert("RGBA")
                background.paste(
                    img, mask=img.split()[-1] if img.mode == "RGBA" else None
                )
                img = background
            elif img.mode != "RGB":
                img = img.convert("RGB")
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ PNG
            png_data = io.BytesIO()
            img.save(png_data, format="PNG", optimize=True)
            png_data.seek(0)
            return png_data
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
        # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        image_data.seek(0)
        return image_data


async def save_image_from_data(image_data: bytes, filename: str) -> str:
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ –±–∏–Ω–∞—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É"""
    file_path = f"{filename}.png"
    with open(file_path, "wb") as f:
        f.write(image_data)
    return file_path


def initialize_user_context(user_id: int, current_mode: str):
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —Ä–µ–∂–∏–º–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    if user_id not in user_contexts:
        user_contexts[user_id] = {}

    if current_mode not in user_contexts[user_id]:
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ä–µ–∂–∏–º–æ–≤
        if current_mode == "ai_file":
            system_message = (
                "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ –∞–Ω–∞–ª–∏–∑—É –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."
                "–û—Ç–≤–µ—á–∞–π –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –∫–∞—Å–∞—Ç–µ–ª—å–Ω–æ "
                "—Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞."
            )
        elif current_mode == "chat":
            # –î–ª—è —Ä–µ–∂–∏–º–∞ —á–∞—Ç–∞ –≤ file_analysis –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥—Ä—É–≥–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            system_message = (
                "You are a helpful assistant. "
                "Use web search only when your knowledge may be outdated "
                "or when the user explicitly asks for fresh data."
            )
        elif current_mode == "image":
            system_message = "–¢—ã –ø–æ–º–æ–≥–∞–µ—à—å –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è."
        elif current_mode == "edit":
            system_message = (
                "–¢—ã –ø–æ–º–æ–≥–∞–µ—à—å —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é Gemini."
            )
        else:
            system_message = "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫."

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å —Å–∏—Å—Ç–µ–º–Ω—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º
        user_contexts[user_id][current_mode] = [
            {"role": "system", "content": system_message}
        ]


async def edit_image_with_gemini(
    original_image: io.BytesIO, prompt: str
) -> str:
    """–†–µ–¥–∞–∫—Ç–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é Gemini 2.5 Flash"""
    model_name = models_config.MODELS["edit"]  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω—Å—Ç–∞–Ω—Ç—É
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É –ø—Ä–æ–º–ø—Ç–∞ –Ω–∞ —Ç–æ–∫–µ–Ω—ã
        prompt_tokens = token_utils.token_counter.count_openai_tokens(
            prompt, model_name
        )
        max_tokens = token_utils.get_token_limit(model_name)

        if prompt_tokens > max_tokens:
            # –û–±—Ä–µ–∑–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–æ –¥–æ–ø—É—Å—Ç–∏–º–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
            avg_token_size = 4  # —Å—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä —Ç–æ–∫–µ–Ω–∞ –≤ —Å–∏–º–≤–æ–ª–∞—Ö
            max_chars = max_tokens * avg_token_size
            prompt = prompt[:max_chars]

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è Gemini
        original_image.seek(0)
        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å Gemini
        model = genai.GenerativeModel(model_name)
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è Gemini
        gemini_prompt = f"""
        –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –≤—ã–ø–æ–ª–Ω–∏ —Å–ª–µ–¥—É—é—â–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è: {prompt}
        –í–∞–∂–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏:
        1. –í–Ω–µ—Å–∏ –∏–º–µ–Ω–Ω–æ —Ç–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –∑–∞–ø—Ä–æ—à–µ–Ω—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º
        2. –°–æ—Ö—Ä–∞–Ω–∏ –æ–±—â–∏–π —Å—Ç–∏–ª—å –∏ –∫–∞—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        3. –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –Ω–µ—è—Å–µ–Ω, —É—Ç–æ—á–Ω–∏ —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        4. –í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ –∏–∑–º–µ–Ω–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        """
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –ø—Ä–æ–º–ø—Ç –≤ Gemini
        response = model.generate_content(
            [
                gemini_prompt,
                {"mime_type": "image/png", "data": original_image.getvalue()},
            ]
        )
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –æ—Ç–≤–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        if hasattr(response, "candidates") and response.candidates:
            for part in response.candidates[0].content.parts:
                if hasattr(part, "inline_data"):
                    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                    return part.inline_data.data
                elif hasattr(part, "text"):
                    # –ï—Å–ª–∏ Gemini –≤–µ—Ä–Ω—É–ª —Ç–µ–∫—Å—Ç –≤–º–µ—Å—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                    raise Exception(
                        f"""
                        –ò–ò –≤–µ—Ä–Ω—É–ª —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –≤–º–µ—Å—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:
                        {part.text}"""
                    )
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –æ—Ç–≤–µ—Ç–µ
        raise Exception("Gemini –Ω–µ –≤–µ—Ä–Ω—É–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –æ—Ç–≤–µ—Ç–µ")
    except Exception as e:
        raise Exception(
            f"–û—à–∏–±–∫–∞ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é –ò–ò: {str(e)}"
        )


async def handle_edit_mode(
    update: Update,
    context: ContextTypes.DEFAULT_TYPE,
    user_id: int,
    user_message: str,
    cost: int,
    balance: float,
):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è —Ä–µ–∂–∏–º–∞ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å Gemini"""
    edit_data = user_edit_data.get(user_id, {})
    # –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –æ—Ç–ø—Ä–∞–≤–∏–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    if update.message.photo:
        await update.message.reply_text("üîÑ –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ PNG...")
        image_data = await download_and_convert_image(
            update.message.photo[-1].file_id, context
        )
        if edit_data.get("step") == "waiting_image":
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            user_edit_data[user_id]["original_image"] = image_data
            user_edit_data[user_id]["step"] = "waiting_prompt"
            await update.message.reply_text(
                "‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–æ –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –≤ PNG. "
                "–¢–µ–ø–µ—Ä—å –æ–ø–∏—à–∏—Ç–µ, —á—Ç–æ –Ω—É–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ "
                "(–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è Gemini 2.5 Flash)."
            )
        return
    # –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –æ—Ç–ø—Ä–∞–≤–∏–ª —Ç–µ–∫—Å—Ç
    elif update.message.text:
        user_message = update.message.text.strip()
        if edit_data.get("step") == "waiting_prompt":
            await update.message.reply_text("üîÑ –†–µ–¥–∞–∫—Ç–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")
            try:
                original_image = user_edit_data[user_id]["original_image"]
                # –†–µ–¥–∞–∫—Ç–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é Gemini
                edited_image_data = await edit_image_with_gemini(
                    original_image, user_message
                )
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                file_path = await save_image_from_data(
                    edited_image_data, f"edited_{user_id}"
                )
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                with open(file_path, "rb") as photo:
                    await update.message.reply_photo(
                        photo,
                        caption=f"–û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–æ –ø–æ –∑–∞–ø—Ä–æ—Å—É: {user_message}",
                    )
                # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                os.remove(file_path)
                # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                user_edit_data[user_id] = {
                    "step": "waiting_image",
                    "original_image": None,
                }

                # –°–ø–∏—Å—ã–≤–∞–µ–º –º–æ–Ω–µ—Ç—ã –∏ –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –ª–æ–≥
                from billing_utils import check_user_coins, spend_coins

                user_data, coins, giftcoins, balance, cost = (
                    await check_user_coins(user_id, "edit", context)
                )
                spend_coins(
                    user_id,
                    cost,
                    coins,
                    giftcoins,
                    "edit",
                    user_message,
                    f"Image edited with prompt: {user_message}",
                )
            except Exception as e:
                await update.message.reply_text(f"‚ö†Ô∏è {str(e)}")
                # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ
                user_edit_data[user_id] = {
                    "step": "waiting_image",
                    "original_image": None,
                }
            return
        # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –Ω–µ –Ω–∞ —Ç–æ–º —à–∞–≥–µ
        await update.message.reply_text(
            "‚ùå –°–Ω–∞—á–∞–ª–∞ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è."
        )
        return
    # –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –æ—Ç–ø—Ä–∞–≤–∏–ª —á—Ç–æ-—Ç–æ –¥—Ä—É–≥–æ–µ
    await update.message.reply_text(
        "‚ùå –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–ª–∏ —Ç–µ–∫—Å—Ç."
    )


async def handle_ai_file_mode(
    update: Update,
    context: ContextTypes.DEFAULT_TYPE,
    user_id: int,
    user_message: str,
    cost: int,
    balance: float,
):
    """Handle the ai_file mode functionality separately"""
    from billing_utils import spend_coins

    # Check if the message contains a document
    if update.message.document:
        # Get the file
        file = await context.bot.get_file(update.message.document.file_id)

        # Determine file extension
        file_ext = file_utils.get_file_extension(
            update.message.document.file_name
        )
        if file_ext.lower() not in file_utils.SUPPORTED_EXTENSIONS:
            await update.message.reply_text(
                f"‚ùå–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç."
                f" –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è: "
                f"{', '.join(file_utils.SUPPORTED_EXTENSIONS)}"
            )
            return

        # Download file
        file_path = (
            f"temp_file_{user_id}_{update.message.message_id}{file_ext}"
        )
        await file.download_to_drive(file_path)

        try:
            # Extract text from file
            await update.message.reply_text("üìÑ –ò–∑–≤–ª–µ–∫–∞—é —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞...")

            extracted_text = await file_utils.process_uploaded_file(
                file_path, file_ext
            )

            # Store extracted text for later use
            if user_id not in user_file_data:
                user_file_data[user_id] = {}
            user_file_data[user_id]["extracted_text"] = extracted_text

            # Confirm extraction
            await update.message.reply_text(
                f"‚úÖ –§–∞–π–ª –æ–±—Ä–∞–±–æ—Ç–∞–Ω! –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(extracted_text)} —Å–∏–º–≤. "
                "–¢–µ–ø–µ—Ä—å –º–æ–∂–µ—Ç–µ –∑–∞–¥–∞–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã –æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º —Ñ–∞–π–ª–∞."
            )

            # Clean up temporary file
            os.remove(file_path)
        except Exception as e:
            # Clean up temporary file even if there's an error
            if os.path.exists(file_path):
                os.remove(file_path)

            await update.message.reply_text(
                f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞: {str(e)}"
            )
            return
    # Check if the message contains a photo (for OCR of images)
    elif update.message.photo:
        # Get the highest resolution photo
        file = await context.bot.get_file(update.message.photo[-1].file_id)

        # Determine file extension - for photos sent as images,
        # assume it's an image file
        file_ext = ".jpg"  # Telegram converts photos to JPEG

        # Download file
        file_path = (
            f"temp_image_{user_id}_{update.message.message_id}{file_ext}"
        )
        await file.download_to_drive(file_path)

        try:
            # Extract text from image using OCR
            await update.message.reply_text(
                "üîç –í—ã–ø–æ–ª–Ω—è—é OCR —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è..."
            )

            extracted_text = await file_utils.extract_text_from_image(
                file_path
            )

            # Store extracted text for later use
            if user_id not in user_file_data:
                user_file_data[user_id] = {}
            user_file_data[user_id]["extracted_text"] = extracted_text

            # Confirm extraction
            await update.message.reply_text(
                f"‚úÖ –§–∞–π–ª –æ–±—Ä–∞–±–æ—Ç–∞–Ω! –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(extracted_text)} —Å–∏–º."
                "–¢–µ–ø–µ—Ä—å –º–æ–∂–µ—Ç–µ –∑–∞–¥–∞–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã –æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è."
            )

            # Clean up temporary file
            os.remove(file_path)
        except Exception as e:
            # Clean up temporary file even if there's an error
            if os.path.exists(file_path):
                os.remove(file_path)

            await update.message.reply_text(
                f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}"
            )
            return
    elif (
        update.message.text
        and user_id in user_file_data
        and "extracted_text" in user_file_data[user_id]
    ):
        # Process the question about the file content
        user_message = update.message.text.strip()
        extracted_text = user_file_data[user_id]["extracted_text"]

        # Limit the extracted text length to prevent connection errors
        # Calculate max characters based on model's token limit
        model_name = models_config.MODELS.get("ai_file")
        max_tokens = token_utils.get_token_limit(model_name)

        # Rough estimation: 1 token ~ 4 characters,
        # reserve tokens for response and context
        # 1500 reserved for context
        max_chars = min(len(extracted_text), (max_tokens - 1500) * 3)

        if len(extracted_text) > max_chars:
            # Truncate the extracted text and inform the user
            truncated_extracted_text = extracted_text[:max_chars]
            await update.message.reply_text(
                f"üìù –û–±—ä–µ–º —Ñ–∞–π–ª–∞ –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ª–∏–º–∏—Ç. –ò—Å–ø–æ–ª—å–∑—É—é –ø–µ—Ä–≤—É—é "
                f"—á–∞—Å—Ç—å —Ç–µ–∫—Å—Ç–∞ ({max_chars} —Å–∏–º.) –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞."
            )
        else:
            truncated_extracted_text = extracted_text

        # Add file content to the user's question
        augmented_question = (
            f"–§–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–ª–µ–¥—É—é—â–∏–π —Ç–µ–∫—Å—Ç:"
            f" {truncated_extracted_text}\n\n–í–æ–ø—Ä–æ—Å: {user_message}"
        )

        # Prepare messages with truncated history
        # using the augmented question
        model_name = models_config.MODELS.get("ai_file")
        truncated_history = token_utils.truncate_messages_for_token_limit(
            user_contexts[user_id]["ai_file"],
            model=model_name,
            reserve_tokens=1500,
        )
        messages = truncated_history + [
            {"role": "user", "content": augmented_question}
        ]

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –∏—Å—Ç–æ—Ä–∏–∏
        if len(messages) > MAX_CONTEXT_MESSAGES:
            messages = messages[-MAX_CONTEXT_MESSAGES:]

        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–ª–∏–µ–Ω—Ç —á–∞—Ç–∞
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ - —ç—Ç–æ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            if messages and messages[-1]["role"] == "user":
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–∫–µ–Ω—ã –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π
                token_counter = token_utils.token_counter
                total_tokens = token_counter.count_openai_messages_tokens(
                    messages, model_name
                )
                max_tokens = token_utils.get_token_limit(model_name)

                if total_tokens > max_tokens:
                    # –û–±—Ä–µ–∑–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–æ ... [truncated]
                    messages = token_utils.truncate_messages_for_token_limit(
                        messages,
                        model=model_name,
                        reserve_tokens=1500,
                    )

            response = models_config.client_chat.chat.completions.create(
                model=model_name,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å –∏–∑ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã
                messages=messages,
            )
            reply = response.choices[0].message.content

            # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç: –¥–æ–±–∞–≤–ª—è–µ–º –∏ –∑–∞–ø—Ä–æ—Å, –∏ –æ—Ç–≤–µ—Ç
            user_contexts[user_id]["ai_file"].append(
                {"role": "user", "content": augmented_question}
            )
            user_contexts[user_id]["ai_file"].append(
                {"role": "assistant", "content": reply}
            )

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç
            # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã Markdown,
            # —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –æ—à–∏–±–æ–∫
            safe_reply = escape_markdown(reply, version=2)
            await update.message.reply_text(
                safe_reply, parse_mode="MarkdownV2"
            )

            # –°–ø–∏—Å—ã–≤–∞–µ–º –º–æ–Ω–µ—Ç—ã –∏ –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –ª–æ–≥
            from billing_utils import check_user_coins

            user_data, coins, giftcoins, balance, cost = (
                await check_user_coins(user_id, "ai_file", context)
            )
            spend_coins(
                user_id,
                cost,
                coins,
                giftcoins,
                "ai_file",
                user_message,
                safe_reply,
            )
        except Exception as e:
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–∫–∏ "Message is too long" –∏ –¥—Ä—É–≥–∏—Ö
            error_msg = str(e)
            if "too long" in error_msg.lower() or "token" in error_msg.lower():
                # LOGGING ====================
                log_text = f"–û—à–∏–±–∫–∞: –°–æ–æ–±—â–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ: {str(e)}"
                dbbot.log_action(user_id, "ai_file", log_text, 0, balance)
                await update.message.reply_text(
                    "‚ö†Ô∏è –°–æ–æ–±—â–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–æ–∫—Ä–∞—Ç–∏—Ç–µ."
                )
            else:
                # LOGGING ====================
                log_text = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ ChatGPT: {str(e)}"
                dbbot.log_action(user_id, "ai_file", log_text, 0, balance)
                await update.message.reply_text(
                    "‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ ChatGPT."
                )
    else:
        # If user hasn't uploaded a file yet but is in file analysis mode
        await update.message.reply_text(
            "üìÅ –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞. "
            "–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ñ–æ—Ä–º–∞—Ç—ã: PDF, DOCX, TXT, XLSX, XLS"
        )


async def handle_image_mode(
    update: Update,
    context: ContextTypes.DEFAULT_TYPE,
    user_id: int,
    user_message: str,
    cost: int,
    coins: int,
    giftcoins: int,
    balance: float,
):
    """Handle the image mode functionality separately"""
    from billing_utils import spend_coins

    # –†–µ–∂–∏–º –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    await update.message.reply_text("üé® –ì–µ–Ω–µ—Ä–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")
    try:
        image_url = await models_config.generate_image(user_message)
        await update.message.reply_photo(
            image_url, caption=f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –ø–æ –∑–∞–ø—Ä–æ—Å—É: {user_message}"
        )
        # –°–ø–∏—Å—ã–≤–∞–µ–º –º–æ–Ω–µ—Ç—ã –∏ –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –ª–æ–≥
        spend_coins(user_id, cost, coins, giftcoins, "image", user_message, "")
    except Exception as e:
        # LOGGING ====================
        log_text = f"‚ö†Ô∏è {str(e)}"
        dbbot.log_action(user_id, "image", log_text, 0, balance)
        await update.message.reply_text(f"‚ö†Ô∏è {str(e)}")


async def handle_chat_mode(
    update: Update,
    context: ContextTypes.DEFAULT_TYPE,
    user_id: int,
    user_message: str,
    cost: int,
    coins: int,
    giftcoins: int,
    balance: float,
):
    """Handle the chat mode functionality separately"""
    from billing_utils import spend_coins

    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é —Å –≤–µ–±-–ø–æ–∏—Å–∫–æ–º –¥–ª—è —Ä–µ–∂–∏–º–∞ chat
        reply = models_config.ask_gpt51_with_web_search(
            user_message, enable_web_search=True
        )

        # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç: –¥–æ–±–∞–≤–ª—è–µ–º –∏ –∑–∞–ø—Ä–æ—Å, –∏ –æ—Ç–≤–µ—Ç
        user_contexts[user_id]["chat"].append(
            {"role": "user", "content": user_message}
        )
        user_contexts[user_id]["chat"].append(
            {"role": "assistant", "content": reply}
        )

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç
        # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã Markdown, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –æ—à–∏–±–æ–∫
        safe_reply = escape_markdown(reply, version=2)
        await update.message.reply_text(safe_reply, parse_mode="MarkdownV2")

        # –°–ø–∏—Å—ã–≤–∞–µ–º –º–æ–Ω–µ—Ç—ã –∏ –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –ª–æ–≥
        spend_coins(
            user_id,
            cost,
            coins,
            giftcoins,
            "chat",
            user_message,
            safe_reply,
        )
    except Exception as e:
        # LOGGING ====================
        log_text = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ ChatGPT: {str(e)}"
        dbbot.log_action(user_id, "chat", log_text, 0, balance)
        await update.message.reply_text("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ ChatGPT.")


async def handle_general_mode(
    update: Update,
    context: ContextTypes.DEFAULT_TYPE,
    user_id: int,
    user_message: str,
    current_mode: str,
    cost: int,
    coins: int,
    giftcoins: int,
    balance: float,
):
    """Handle the general mode functionality for other modes"""
    from billing_utils import spend_coins

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
    model_name = models_config.MODELS.get(current_mode)
    truncated_history = token_utils.truncate_messages_for_token_limit(
        user_contexts[user_id][current_mode],
        model=model_name,
        reserve_tokens=1500,
    )
    messages = truncated_history + [{"role": "user", "content": user_message}]

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –∏—Å—Ç–æ—Ä–∏–∏
    if len(messages) > MAX_CONTEXT_MESSAGES:
        messages = messages[-MAX_CONTEXT_MESSAGES:]

    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–ª–∏–µ–Ω—Ç —á–∞—Ç–∞
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ - —ç—Ç–æ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        if messages and messages[-1]["role"] == "user":
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–∫–µ–Ω—ã –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π
            token_counter = token_utils.token_counter
            total_tokens = token_counter.count_openai_messages_tokens(
                messages, model_name
            )
            max_tokens = token_utils.get_token_limit(model_name)

            if total_tokens > max_tokens:
                # –û–±—Ä–µ–∑–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–æ –ø—Ä–∏–µ–º–ª–µ–º–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
                messages = token_utils.truncate_messages_for_token_limit(
                    messages,
                    model=model_name,
                    reserve_tokens=1500,  # –û—Å—Ç–∞–≤–ª—è–µ–º –º–µ—Å—Ç–æ –¥–ª—è –æ—Ç–≤–µ—Ç–∞
                )

        response = models_config.client_chat.chat.completions.create(
            model=model_name,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å –∏–∑ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã
            messages=messages,
        )
        reply = response.choices[0].message.content

        # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç: –¥–æ–±–∞–≤–ª—è–µ–º –∏ –∑–∞–ø—Ä–æ—Å, –∏ –æ—Ç–≤–µ—Ç
        user_contexts[user_id][current_mode].append(
            {"role": "user", "content": user_message}
        )
        user_contexts[user_id][current_mode].append(
            {"role": "assistant", "content": reply}
        )

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç
        # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã Markdown, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –æ—à–∏–±–æ–∫
        safe_reply = escape_markdown(reply, version=2)
        await update.message.reply_text(safe_reply, parse_mode="MarkdownV2")

        # –°–ø–∏—Å—ã–≤–∞–µ–º –º–æ–Ω–µ—Ç—ã –∏ –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –ª–æ–≥
        spend_coins(
            user_id,
            cost,
            coins,
            giftcoins,
            current_mode,
            user_message,
            safe_reply,
        )
    except Exception as e:
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–∫–∏ "Message is too long" –∏ –¥—Ä—É–≥–∏—Ö
        error_msg = str(e)
        if "too long" in error_msg.lower() or "token" in error_msg.lower():
            # LOGGING ====================
            log_text = f"–û—à–∏–±–∫–∞: –°–æ–æ–±—â–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ: {str(e)}"
            dbbot.log_action(user_id, current_mode, log_text, 0, balance)
            await update.message.reply_text(
                "‚ö†Ô∏è –°–æ–æ–±—â–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–æ–∫—Ä–∞—Ç–∏—Ç–µ."
            )
        else:
            # LOGGING ====================
            log_text = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ ChatGPT: {str(e)}"
            dbbot.log_action(user_id, current_mode, log_text, 0, balance)
            await update.message.reply_text(
                "‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ ChatGPT."
            )


async def handle_voice_message(
    update: Update,
    context: ContextTypes.DEFAULT_TYPE,
    user_id: int,
    current_mode: str,
    balance: float,
):
    """Handle voice message transcription and return the transcribed text"""
    # –°–∫–∞—á–∏–≤–∞–µ–º –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
    voice_file = await context.bot.get_file(update.message.voice.file_id)
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –µ–≥–æ –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
    file_path = f"voice_{user_id}_{update.message.message_id}.ogg"
    await voice_file.download_to_drive(file_path)

    try:
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ç–µ–∫—Å—Ç
        user_message = await models_config.transcribe_voice(file_path)
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        os.remove(file_path)
        return user_message
    except Exception as e:
        # LOGGING ====================
        log_text = "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ."
        dbbot.log_action(user_id, current_mode, log_text, 0, balance)
        print("–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏:", e)
        await update.message.reply_text(
            "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ."
        )
        return None


async def handle_message_or_voice(
    update: Update, context: ContextTypes.DEFAULT_TYPE
):
    user_id = update.effective_user.id
    # –ï—Å–ª–∏ —Ä–µ–∂–∏–º –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–µ–∂–∏–º —á–∞—Ç–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    if user_id not in user_modes:
        user_modes[user_id] = "chat"

    current_mode = user_modes[user_id]
    print(f"we are in handle message ot voice mode {current_mode}")
    # Continue with standard processing using the augmented question
    # --- ‚úÖ –ü–†–û–í–ï–†–ö–ê –ù–ê–õ–ò–ß–ò–Ø –ú–û–ù–ï–¢ ---
    user_data, coins, giftcoins, balance, cost = (
        await billing_utils.check_user_coins(user_id, current_mode, context)
    )
    if user_data is None:
        return  # ‚ùå –ü—Ä–µ—Ä—ã–≤–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ, –µ—Å–ª–∏ –º–æ–Ω–µ—Ç –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç
    # --- ‚úÖ –ü–†–û–í–ï–†–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê ---

    # === –ì–ê–†–ê–ù–¢–ò–†–û–í–ê–ù–ù–ê–Ø –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ö–û–ù–¢–ï–ö–°–¢–ê –î–õ–Ø –¢–ï–ö–£–©–ï–ì–û –†–ï–ñ–ò–ú–ê
    initialize_user_context(user_id, current_mode)

    # Handle file uploads in file_analysis mode
    if current_mode == "ai_file":
        await handle_ai_file_mode(
            update,
            context,
            user_id,
            "",
            cost,
            balance,
        )
        return  # End here for file analysis mode

    # --- ‚úÖ –ü–†–û–í–ï–†–ö–ê –ù–ê–õ–ò–ß–ò–Ø –ú–û–ù–ï–¢ ---
    user_data, coins, giftcoins, balance, cost = (
        await billing_utils.check_user_coins(user_id, current_mode, context)
    )
    if user_data is None:
        return  # ‚ùå –ü—Ä–µ—Ä—ã–≤–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ, –µ—Å–ª–∏ –º–æ–Ω–µ—Ç –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç
    # --- ‚úÖ –ü–†–û–í–ï–†–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê ---

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∂–∏–º–∞ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    if current_mode == "edit":
        await handle_edit_mode(
            update,
            context,
            user_id,
            "",
            cost,
            balance
        )
        return

    # === –ì–ê–†–ê–ù–¢–ò–†–û–í–ê–ù–ù–ê–Ø –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ö–û–ù–¢–ï–ö–°–¢–ê –î–õ–Ø –¢–ï–ö–£–©–ï–ì–û –†–ï–ñ–ò–ú–ê ===
    initialize_user_context(user_id, current_mode)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –≥–æ–ª–æ—Å–æ–≤—ã–º
    if update.message.voice:
        result = await handle_voice_message(
            update, context, user_id, current_mode, balance
        )
        if result is None:
            return  # Error occurred in voice handling
        user_message = result
    elif update.message.text:
        # –û–±—ã—á–Ω–æ–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        user_message = update.message.text.strip()
    else:
        return  # –ù–µ —Ç–µ–∫—Å—Ç –∏ –Ω–µ –≥–æ–ª–æ—Å

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∂–∏–º–∞
    if current_mode == "image":
        await handle_image_mode(
            update,
            context,
            user_id,
            user_message,
            cost,
            coins,
            giftcoins,
            balance,
        )
        return

    # –î–ª—è —Ä–µ–∂–∏–º–∞ chat –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –≤–µ–±-–ø–æ–∏—Å–∫–∞
    if current_mode == "chat":
        await handle_chat_mode(
            update,
            context,
            user_id,
            user_message,
            cost,
            coins,
            giftcoins,
            balance,
        )
        return
    else:
        # –î–ª—è –¥—Ä—É–≥–∏—Ö —Ä–µ–∂–∏–º–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—â—É—é –ª–æ–≥–∏–∫—É
        await handle_general_mode(
            update,
            context,
            user_id,
            user_message,
            current_mode,
            cost,
            coins,
            giftcoins,
            balance,
        )
