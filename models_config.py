"""Configuration for AI models used by the bot."""
import os
from dotenv import load_dotenv
import google.generativeai as genai
from openai import OpenAI
import token_utils

# –ó–∞–≥—Ä—É–∑–∏—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞ .env
load_dotenv()

# –ü–æ–ª—É—á–∞–µ–º —Ç–æ–∫–µ–Ω—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ä–µ–∂–∏–º–æ–≤
OPENAI_API_KEY_CHAT = os.getenv("OPENAI_API_KEY")
OPENAI_API_KEY_IMAGE = os.getenv("OPENAI_API_KEY_IMAGE")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤ OpenAI –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ä–µ–∂–∏–º–æ–≤
client_chat = OpenAI(api_key=OPENAI_API_KEY_CHAT)
client_image = OpenAI(api_key=OPENAI_API_KEY_IMAGE)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ Gemini
genai.configure(api_key=GEMINI_API_KEY)

# –ú–æ–¥–µ–ª–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ä–µ–∂–∏–º–æ–≤
MODELS = {
    "chat": "gpt-5.1",
    "image": "dall-e-3",
    "edit": "gemini-2.5-flash-preview-image",
    "file_analysis": "gpt-5.1",
}

# Cost per message
COST_PER_MESSAGE = {
    "chat": 2,
    "image": 5,
    "edit": 6,
    "file_analysis": 3,
}


async def get_gemini_models_info() -> str:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö Gemini –≤ –≤–∏–¥–µ —Å—Ç—Ä–æ–∫–∏.
    """
    try:
        models = genai.list_models()
        lines = ["ü§ñ –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ Gemini:\n"]
        for model in models:
            model_id = model.name.split("/")[-1]
            input_tokens = model.input_token_limit
            output_tokens = model.output_token_limit
            methods = ", ".join(model.supported_generation_methods)
            temp = (
                f"{model.temperature:.1f}"
                if model.temperature
                else "–Ω–µ –∑–∞–¥–∞–Ω–∞"
            )

            lines.append(
                f"üîπ *{model_id}*"
                f"\n   –í—Ö–æ–¥: `{input_tokens}` —Ç–æ–∫–µ–Ω–æ–≤"
                f"\n   –í—ã—Ö–æ–¥: `{output_tokens}` —Ç–æ–∫–µ–Ω–æ–≤"
                f"\n   –†–µ–∂–∏–º—ã: `{methods}`"
                f"\n   –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: `{temp}`"
                f"\n"
            )
        return "\n".join(lines)
    except Exception as e:
        return f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–µ–π Gemini: `{str(e)}`"


async def get_openai_models_info() -> str:
    try:
        # –£–ë–ò–†–ê–ï–ú await ‚Äî –≤—ã–∑–æ–≤ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π!
        models = client_image.models.list()
        lines = ["ü§ñ –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ OpenAI:\n"]
        for model in models:
            lines.append(f"üîπ `{model.id}`")
        return "\n".join(lines)
    except Exception as e:
        return f"‚ùå –û—à–∏–±–∫–∞: `{e}`"


def ask_gpt51_with_web_search(
    query: str, enable_web_search: bool = True
) -> str:
    """
    –ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å GPT-5.1 —Å –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º –ø–æ–∏—Å–∫–æ–º –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ.

    :param query: –¢–µ–∫—Å—Ç –≤–æ–ø—Ä–æ—Å–∞.
    :param enable_web_search:
        –ï—Å–ª–∏ True ‚Äî –º–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–ø–æ–∏—Å–∫.
        –ï—Å–ª–∏ False ‚Äî —Ç–æ–ª—å–∫–æ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –∑–Ω–∞–Ω–∏—è, –±–µ–∑ –ø–æ–∏—Å–∫–∞.
    :return: –¢–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç –º–æ–¥–µ–ª–∏.
    """
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É –∑–∞–ø—Ä–æ—Å–∞ –∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –µ–≥–æ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
    model_name = "gpt-5.1"
    max_tokens = token_utils.get_token_limit(model_name)
    query_tokens = token_utils.token_counter.count_openai_tokens(
        query, model_name
    )

    if query_tokens > max_tokens:
        # –û–±—Ä–µ–∑–∞–µ–º –∑–∞–ø—Ä–æ—Å –¥–æ –¥–æ–ø—É—Å—Ç–∏–º–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
        avg_token_size = 4  # —Å—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä —Ç–æ–∫–µ–Ω–∞ –≤ —Å–∏–º–≤–æ–ª–∞—Ö
        max_chars = max_tokens * avg_token_size
        query = query[:max_chars]

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤: —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ä–∞–∑—Ä–µ—à—ë–Ω –ø–æ–∏—Å–∫
    tools = (
        [
            {
                "type": "web_search",
                # –ú–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å: —Ñ–∏–ª—å—Ç—Ä—ã, —è–∑—ã–∫, —Ä–µ–≥–∏–æ–Ω –∏ —Ç.–ø.
            }
        ]
        if enable_web_search
        else []
    )

    # –í—ã–±–æ—Ä –ø–æ–≤–µ–¥–µ–Ω–∏—è: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
    tool_choice = "auto" if enable_web_search else "none"

    response = client_chat.responses.create(
        model="gpt-5.1",  # –∏–ª–∏ "gpt-5.1-thinking"
        tools=tools,
        tool_choice=tool_choice,
        input=query,
        instructions=(
            "You are a helpful assistant. "
            "Use web search only when your knowledge may be outdated "
            "or when the user explicitly asks for fresh data."
        ),
        temperature=0.4,
        # include sources only if web search is enabled
        include=(
            ["web_search_call.action.sources"] if enable_web_search else []
        ),
    )

    return response.output_text
